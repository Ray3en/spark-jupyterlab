{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dbd35c-c05b-4e74-9cb5-a3fc2a0e5351",
   "metadata": {},
   "source": [
    "### Start SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf1a3f-7641-4f37-9935-eb1cd80bf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"pyspark_local\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print(\"Активные Spark сессии:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81f1bb-00ec-4840-8998-0d2056e81e26",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2030acf5-9a3b-445b-87d3-9727ad4e3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/orders.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(PATH).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83700e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(PATH, sep=',', header=True).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9440ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(PATH, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14377e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df\\\n",
    "    .withColumnRenamed(\"direction_eng\", \"direction\")\\\n",
    "    .withColumnRenamed(\"measure_eng\", \"measure\")\n",
    "\n",
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1caf03e-fc30-4bc3-ac05-19fbc6336538",
   "metadata": {},
   "source": [
    "### PrintSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a90f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- registration_date: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf633ef-415f-417d-b3b8-fb56b5109029",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df \\\n",
    "    .withColumnRenamed(\"registration_date\", \"registered_at\") \\\n",
    "    .withColumnRenamed(\"birthdate\", \"dob\") \\\n",
    "    .withColumnRenamed(\"country_code\", \"iso_code\")\n",
    "\n",
    "result.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464d803",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67966ef-90cd-42d4-a260-236b60220312",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select('company').distinct().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d080a-b5e8-45cb-aec0-8e03eb5e5bb7",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94e8c7-41df-4a64-a0db-e302111f05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\\\n",
    "    .groupBy('country')\\\n",
    "    .agg(F.count('*').alias('total_rows'))\\\n",
    "    .orderBy(F.col('total_rows').desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f564628-8bf3-45cb-95f2-6f80ed4cec6a",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2a20f-8af3-439a-a487-6c7d3fbcc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Два варианта написании фильтрации\n",
    "df_de_salary = result\\\n",
    "    .where(F.col(\"country\") == \"Korea\") \\\n",
    "    .where(F.col(\"salary\").isNotNull()) \\\n",
    "\n",
    "df_de_salary2 = result \\\n",
    "    .where('country = \"Korea\"') \\\n",
    "    .where('salary IS NOT NULL')\n",
    "\n",
    "print('df_de_salary',df_de_salary.count())\n",
    "print('df_de_salary2',df_de_salary2.count())\n",
    "print(df_de_salary.count() == df_de_salary2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b564c-86f8-4633-a5ff-5cf8da7b6eea",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7058846-f7b2-4a9e-9388-3a5a9ed26bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------------+---------------------------------------------+-----------------------------+-----------------+---------------------------+-----------------------------+----------+-------+------------------------------------+------+--------+\n",
      "|name             |email                   |address                                      |registered_at                |phone            |company                    |job                          |dob       |country|uuid                                |salary|iso_code|\n",
      "+-----------------+------------------------+---------------------------------------------+-----------------------------+-----------------+---------------------------+-----------------------------+----------+-------+------------------------------------+------+--------+\n",
      "|Rhonda Foley     |jonathan92@example.org  |1234 Cox Light Suite 381, Brownfurt, NV 24776|2024-08-30T00:00:00.000+03:00|513-361-0719     |White-Oneill               |Academic librarian           |2006-08-07|Korea  |757b9bd8-1aa7-4241-9710-77d285870a2d|2300  |LV      |\n",
      "|Christine Hopkins|davisvanessa@example.com|6319 Jacob Dale Suite 289, Danaside, NM 89761|2024-09-03T00:00:00.000+03:00|(607)860-3600x174|Parker, Mcdowell and Moreno|Development worker, community|2006-05-22|Korea  |b629f5c4-05c1-45fd-bd4c-218ad628d2c1|14000 |PE      |\n",
      "+-----------------+------------------------+---------------------------------------------+-----------------------------+-----------------+---------------------------+-----------------------------+----------+-------+------------------------------------+------+--------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "df_de_salary.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "945d5e8c-c146-4221-9a29-9279d6911de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'email',\n",
       " 'address',\n",
       " 'registered_at',\n",
       " 'phone',\n",
       " 'company',\n",
       " 'job',\n",
       " 'dob',\n",
       " 'country',\n",
       " 'uuid',\n",
       " 'salary',\n",
       " 'iso_code']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de_salary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d62869a2-9781-428d-9292-6775b5bd5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-------+--------+------+-----------------------------+---------------------------+-----------------+------------------------+----------+\n",
      "|registered_at                |country|iso_code|salary|job                          |company                    |name             |email                   |reg_date  |\n",
      "+-----------------------------+-------+--------+------+-----------------------------+---------------------------+-----------------+------------------------+----------+\n",
      "|2024-08-30T00:00:00.000+03:00|Korea  |LV      |2300  |Academic librarian           |White-Oneill               |Rhonda Foley     |jonathan92@example.org  |2024-08-30|\n",
      "|2024-09-03T00:00:00.000+03:00|Korea  |PE      |14000 |Development worker, community|Parker, Mcdowell and Moreno|Christine Hopkins|davisvanessa@example.com|2024-09-03|\n",
      "+-----------------------------+-------+--------+------+-----------------------------+---------------------------+-----------------+------------------------+----------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "final = df_de_salary.select(\n",
    "    'registered_at',\n",
    "    'country',\n",
    "    'iso_code',\n",
    "    'salary',\n",
    "    'job',\n",
    "    'company',\n",
    "    'name',\n",
    "    'email',\n",
    "    F.col('registered_at').cast('date').alias('reg_date')\n",
    ")\n",
    "\n",
    "final.show(2, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8eff1058-85c4-4f3a-ad43-b3e69f41abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во партиций 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Сохранение неконтроллируемое по кол-ву файлов\n",
    "final\\\n",
    "    .write\\\n",
    "    .format('csv')\\\n",
    "    .options(header='True', sep=';')\\\n",
    "    .csv('data/final_no_control')\n",
    "\n",
    "partition_num = final.rdd.getNumPartitions()\n",
    "print(f'Кол-во партиций {partition_num}')\n",
    "\n",
    "# Сохранение контроллируемое по кол-ву файлов - ОДИН ФАЙЛ\n",
    "# final\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .format('csv')\\\n",
    "#     .options(header='True', sep=';')\\\n",
    "#     .csv('data/final_one_file') \n",
    "\n",
    "# partition_num = final.coalesce(1).rdd.getNumPartitions()\n",
    "# print(f'Кол-во партиций {partition_num}')\n",
    "\n",
    "\n",
    "# Сохранения с партицированием\n",
    "# final\\\n",
    "#     .write\\\n",
    "#     .partitionBy('load_date')\\\n",
    "#     .format('csv')\\\n",
    "#     .options(header='True', sep=';')\\\n",
    "#     .csv('data/final_partitioned')\n",
    "\n",
    "# print_df = final.select('load_date').distinct()\n",
    "# print(f'Load_date distinct: {print_df.count()}')\n",
    "\n",
    "\n",
    "# Сохранения с партицированием и repartition внутри самой партиции\n",
    "# final\\\n",
    "#     .repartition(1, 'load_date')\\\n",
    "#     .write\\\n",
    "#     .partitionBy('load_date')\\\n",
    "#     .format('csv')\\\n",
    "#     .options(header='True', sep=';')\\\n",
    "#     .csv('data/final_partitioned_repart')\n",
    "\n",
    "# partition_num = final.repartition(1, 'load_date').rdd.getNumPartitions()\n",
    "# print(f'Кол-во партиций {partition_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f71e8-ab17-4104-85d1-fc55f3f9a43f",
   "metadata": {},
   "source": [
    "### Read Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70e3d82e-b20d-4e3d-8ad9-e752662da308",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_no_control = spark\\\n",
    "                        .read\\\n",
    "                        .csv('data/final_no_control/', header=True, sep=';')\\\n",
    "                        .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_final_one_file = spark\\\n",
    "                            .read\\\n",
    "                            .csv('data/final_one_file/', header=True, sep=';')\\\n",
    "                            .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_partitioned = spark\\\n",
    "                        .read\\\n",
    "                        .csv('data/final_partitioned', header=True, sep=';')\\\n",
    "                        .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_partitioned_repart = spark\\\n",
    "                                .read\\\n",
    "                                .csv('data/final_partitioned_repart', header=True, sep=';')\\\n",
    "                                .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "\n",
    "reader_no_control.count() # number of files read: 16 | size of files read: 88.4 MiB | 2.5 s (90 ms, 301 ms, 384 ms)\n",
    "\n",
    "reader_final_one_file.count() # number of files read: 1 | size of files read: 88.4 MiB | 3.2 s (306 ms, 407 ms, 420 ms )\n",
    "\n",
    "reader_partitioned.count() # number of files read: 16 | size of files read: 16.4 MiB | 305 ms (32 ms, 39 ms, 54 ms )\n",
    "\n",
    "reader_partitioned_repart.count() # number of files read: 1 | size of files read: 16.4 MiB | 179 ms (9 ms, 43 ms, 44 ms )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f5468",
   "metadata": {},
   "source": [
    "### JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (14000, \"Северный\"),\n",
    "    (11000, \"Южный\"),\n",
    "    (10000, \"Восточный\"),\n",
    "    (26000, \"Западный\"),\n",
    "    (56000, \"Центральный\")\n",
    "]\n",
    "\n",
    "region_df = spark.createDataFrame(data, schema='region_id long, name string')\n",
    "\n",
    "region_df.show()\n",
    "\n",
    "\n",
    "customs_data = spark\\\n",
    "                .read\\\n",
    "                .csv('data/customs_data.csv', header=True, sep=';')\n",
    "\n",
    "customs_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5939bc3f-1bb0-4240-afff-da26e9818381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключим автоматический Broadcast JOIN\n",
    "import time\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42d681ee-cd9b-4caa-8dc3-6b1853f03a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замерим выполнение запроса без broadcast join\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "customs_data.join(region_df, customs_data.region==region_df.region_id, \"left\").count()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Elapsed time for join operation: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b661180-bcac-439b-a2bd-df3b1f8573c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замерим выполнение запроса c broadcast join\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "customs_data.join(F.broadcast(region_df), customs_data.region == region_df.region_id, \"left\").count()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Elapsed time for broadcast join operation: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9bc17",
   "metadata": {},
   "source": [
    "### Cache | Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c6344db",
   "metadata": {},
   "outputs": [],
   "source": [
    "customs_data.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2be3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "customs_data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eedfda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "customs_data.persist(StorageLevel.DISK_ONLY).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9566a5",
   "metadata": {},
   "source": [
    "### Repartition & Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39c4a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,'one'), (2,'two'), (3,'three'), (4,'four'),\n",
    "        (5,'five'), (6,'six'), (7, 'seven'), (8, 'eight'),\n",
    "        (9, 'nine')]\n",
    "\n",
    "df = spark.createDataFrame(data, ['id', 'number'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44e33bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Намеренно перемешаем и поделим на 8 разделов\n",
    "mix = df.repartition(8)\n",
    "mix.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "978ee041",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.repartition(3).rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1eb8bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.coalesce(3).rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "255abe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUT OF MEMORY\n",
    "\n",
    "d = spark.read.csv('data/customs_data.csv', header=True, sep='\\t')\n",
    "d.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bb1f01e-5698-432a-b725-78ef3c063e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
